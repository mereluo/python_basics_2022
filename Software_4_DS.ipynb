{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e8f2e5",
   "metadata": {},
   "source": [
    "# Sofeware Engineering for Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a52d9",
   "metadata": {},
   "source": [
    "* **Modularity**\n",
    "    * Readability, maintainability, solve problem only once\n",
    "    * Object, Class, Package\n",
    "* **Documentation**\n",
    "    * Prevent confusion and frustration\n",
    "* **Testing**\n",
    "    * Find & fix more bugs, run tests anytime/anywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949a4ce",
   "metadata": {},
   "source": [
    "## 1. PEP 8 coding style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e2e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# PEP 8 coding style\n",
    "!pip install pycodestyle\n",
    "\n",
    "# pycodestyle xx.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b526f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# Import needed package\n",
    "import pycodestyle\n",
    "\n",
    "# Create a StyleGuide instance\n",
    "style_checker = pycodestyle.StyleGuide()\n",
    "\n",
    "# Run PEP 8 check on multiple files\n",
    "result = style_checker.check_files(['DataTypes.ipynb',\n",
    "                                    'Efficient_Python.ipynb'])\n",
    "\n",
    "# Print result of PEP 8 style check\n",
    "print(result.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bcc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install flake8 pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9ad885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade47426",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on\n",
    "# start to check jupyter notebook's style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458279b",
   "metadata": {},
   "source": [
    "## 2. Writing First Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c02e7",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"py_package.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365df2e3",
   "metadata": {},
   "source": [
    "### 2.1 Importing functions\n",
    "If you wrote two functions for you package in the file `counter_utils.py` named `plot_counter` & `sum_counters`, which of the following lines would correctly import these functions in `__init__.py` using relative syntax? <br/>\n",
    "\n",
    "`from .counter_utils import plot_counter, sum_counters`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b889bbc",
   "metadata": {},
   "source": [
    "### 2.2 requirements.txt \n",
    "> It can help your package be more portable by allowing your users to easily recreate its intended environment\n",
    "\n",
    "E.g. <br/>\n",
    "requirements = \"\"\" <br/>\n",
    "`matplotlib`>=3.0.0 <br/>\n",
    "`numpy`==1.15.4 <br/>\n",
    "`pandas`<=0.22.0 <br/>\n",
    "`pycodestyle` <br/>\n",
    "\"\"\" <br/>\n",
    "\n",
    "`pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47c8ca",
   "metadata": {},
   "source": [
    "### 2.3 setup.py\n",
    "\n",
    "**# Import needed function from setuptools**<br/>\n",
    "`from setuptools import setup`\n",
    "\n",
    "**# Create proper setup to be used by pip**<br/>\n",
    "`setup(name='text_analyzer',\n",
    "      version='0.0.1',\n",
    "      description='Perform and visualize a text anaylsis.',\n",
    "      author='meredith',\n",
    "      author_email='sss@gmail.com',\n",
    "      packages=['text_analyzer']),\n",
    "      install_requires=['numpy']`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a6222",
   "metadata": {},
   "source": [
    "## 3. Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3794c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Document class\n",
    "class Document:\n",
    "    \"\"\"A class for text analysis\n",
    "    \n",
    "    :param text: string of text to be analyzed\n",
    "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
    "    \"\"\"\n",
    "    # Method to create a new instance of MyClass\n",
    "    def __init__(self, text):\n",
    "        # Store text parameter to the text attribute\n",
    "        self.text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a288af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic linear regression example. #DataCamp #DataScience #Python #sklearn\n"
     ]
    }
   ],
   "source": [
    "datacamp_tweet = 'Basic linear regression example. #DataCamp #DataScience #Python #sklearn'\n",
    "\n",
    "# Create an instance of Document with datacamp_tweet\n",
    "my_document = Document(text=datacamp_tweet)\n",
    "# Print the text attribute of the Document instance\n",
    "print(my_document.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66020b96",
   "metadata": {},
   "source": [
    "### non-public method using _method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92bb0050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c110251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "class Document:\n",
    "  def __init__(self, text):\n",
    "    self.text = text\n",
    "    # Tokenize the document with non-public tokenize method\n",
    "    self.tokens = self._tokenize()\n",
    "    # Perform word count with non-public count_words method\n",
    "    self.word_counts = self._count_words()\n",
    "\n",
    "  def _tokenize(self):\n",
    "    return word_tokenize(self.text)\n",
    "\n",
    "  # non-public method to tally document's word counts with Counter\n",
    "  def _count_words(self):\n",
    "    return Counter(self.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e17069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datacamp_tweets.txt') as f:\n",
    "    datacamp_tweets = str(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c9a3630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', \"'datacamp_tweets\", '=', '\\\\', \"'\"]\n",
      "[('@', 891), ('#', 331), ('DataCamp', 305), (':', 291), (',', 271)]\n"
     ]
    }
   ],
   "source": [
    "# create a new document instance from datacamp_tweets\n",
    "datacamp_doc = Document(text=datacamp_tweets)\n",
    "\n",
    "# print the first 5 tokens from datacamp_doc\n",
    "print(datacamp_doc.tokens[:5])\n",
    "\n",
    "# print the top 5 most used words in datacamp_doc\n",
    "print(datacamp_doc.word_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a82b8",
   "metadata": {},
   "source": [
    "### Dry principle\n",
    "> Don't repeat yourself\n",
    "\n",
    "With inheritance, we start with a **parent** class and we pass on it's functionality to a **child** class <br/>\n",
    "The **child** class inherits all the methods and attributes of its parent, <br/>\n",
    "and we're able to add additional functionality without affecting the **parent** class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba45a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SocialMedia class that is a child of the `Document class`\n",
    "class SocialMedia(Document):\n",
    "    def __init__(self, text):\n",
    "        Document.__init__(self, text) # need to init the parent class\n",
    "        self.ten_words = self._ten_words() # child's own attributes\n",
    "        self.eleven_words = self._eleven_words()\n",
    "    \n",
    "    def _ten_words(self):\n",
    "        return self.tokens[:10]\n",
    "    \n",
    "    def _eleven_words(self):\n",
    "        return self.tokens[11:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "846c5c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'DataCamp', ']', 'Introduction', 'to', 'H2O', 'AutoML', '--', '>', 'In']\n",
      "['tutorial', ',', 'you', 'will', 'learn', 'about', 'H2O', 'and', 'have', 'a']\n"
     ]
    }
   ],
   "source": [
    "datacamp_sm = SocialMedia(text=datacamp_tweets)\n",
    "\n",
    "print(datacamp_sm.ten_words)\n",
    "print(datacamp_sm.eleven_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c43e672a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ten_words', '_tokenize', 'eleven_words', 'ten_words', 'text', 'tokens']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datacamp_sm)[-7:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9162f186",
   "metadata": {},
   "source": [
    "### Multilevel Inheritance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32dc6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parent:\n",
    "    def __init__(self):\n",
    "        print(\"I'm a parent\")\n",
    "\n",
    "class Child(Parent):\n",
    "    def __init__(self):\n",
    "        Parent.__init__(self) # here we have self\n",
    "        print(\"I'm a child\") \n",
    "\n",
    "class SuperChild(Parent):\n",
    "    def __init__(self):\n",
    "        super().__init__() # here we don't have self\n",
    "        print(\"I'm a super child!\")\n",
    "\n",
    "class Grandchild(SuperChild):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        print('I am a grandchild!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "547fc0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a parent\n",
      "<__main__.Parent object at 0x124c97e50>\n",
      "I'm a parent\n",
      "I'm a child\n",
      "<__main__.Child object at 0x124c97cd0>\n",
      "I'm a parent\n",
      "I'm a super child!\n",
      "<__main__.SuperChild object at 0x124c97e50>\n",
      "I'm a parent\n",
      "I'm a super child!\n",
      "I am a grandchild!\n",
      "<__main__.Grandchild object at 0x124c97cd0>\n"
     ]
    }
   ],
   "source": [
    "print(Parent())\n",
    "print(Child())\n",
    "print(SuperChild())\n",
    "print(Grandchild()) # as a grandchild for super child"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7292772",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "def function(x):\n",
    "    \n",
    "    \"\"\"High level description of function \n",
    "    \n",
    "    Additional details on function\n",
    "    \n",
    "    :param x: description of parameter x \n",
    "    :return: description of return value\n",
    "    \n",
    "    >>> function(example)\n",
    "    example outcome\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fb53bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cee876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, regex=r'[a-zA-z]+'):\n",
    "  \"\"\"\n",
    "  Split text into tokens using a regular expression\n",
    "\n",
    "  :param text: text to be tokenized\n",
    "  :param regex: regular expression used to match tokens using re.findall \n",
    "  :return: a list of resulting tokens\n",
    "\n",
    "  >>> tokenize('the rain in spain')\n",
    "  ['the', 'rain', 'in', 'spain']\n",
    "  \"\"\"\n",
    "  return re.findall(regex, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6258413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'rain', 'in', 'spain']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('the rain in spain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a31bc7",
   "metadata": {},
   "source": [
    "### Unit Testing\n",
    "\n",
    "`doctest`\n",
    "`pytest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b97aa825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 8, in __main__.square\n",
      "Failed example:\n",
      "    square(3)\n",
      "Expected:\n",
      "    9\n",
      "Got:\n",
      "    27\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   1 in __main__.square\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x):\n",
    "    \"\"\"\n",
    "    Square the number x\n",
    "    \n",
    "    :param x: number to square\n",
    "    :return: x squared\n",
    "    \n",
    "    >>> square(3)\n",
    "    9\n",
    "    \"\"\"\n",
    "    return x ** x\n",
    "\n",
    "import doctest\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc5c99",
   "metadata": {},
   "source": [
    "### pytest\n",
    "\n",
    "It searches for files that start or end with the word 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8203bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # working in workdir/tests/test_document.py\n",
    "# from text_analyzer import Document\n",
    "\n",
    "# # Test tokens attribute on Document object\n",
    "# def test_document_tokens():\n",
    "#     doc = Document('a e i o u')\n",
    "    \n",
    "#     assert doc.tokens == ['a','e','i','o','u']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41293f",
   "metadata": {},
   "source": [
    "### Other available tools\n",
    "**Sphinx**: generate beautiful documentation <br/>\n",
    "**Travic CI**: Continuously test your code <br/>\n",
    "**Codecov**: Discover where to improve your projects tests <br/>\n",
    "**Code Climate**: Analyze your code for improvements in readability <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bf86284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for Sphinx\n",
    "# from text_analyzer import Document\n",
    "\n",
    "# class SocialMedia(Document):\n",
    "#     \"\"\"Analyze text data from social media\n",
    "    \n",
    "#     :param text: social media text to analyze\n",
    "\n",
    "#     :ivar hashtag_counts: Counter object containing counts of hashtags used in text\n",
    "#     :ivar mention_counts: Counter object containing counts of @mentions used in text\n",
    "#     \"\"\"\n",
    "#     def __init__(self, text):\n",
    "#         Document.__init__(self, text)\n",
    "#         self.hashtag_counts = self._count_hashtags()\n",
    "#         self.mention_counts = self._count_mentions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
